{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JK-the-Ko/Thermo-Fluid-Dynamics-Experiment/blob/main/2023-2/%EC%97%B4%EC%9C%A0%EC%B2%B4%EA%B3%B5%ED%95%99%EC%8B%A4%ED%97%981_Week13_PyTorch_Denoising_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ97dC_jLHvF"
      },
      "source": [
        "# Denoising Autoencoder Using PyTorch Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX6s-j7fq3hA"
      },
      "source": [
        "## Check NVIDIA GPU Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_I7cz1Sq6S1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST Dataset"
      ],
      "metadata": {
        "id": "1sg71j-zWuau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "UvcYeIfuWwE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset = MNIST(root=\"content\",\n",
        "                     train=True,\n",
        "                     transform=transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()]),\n",
        "                     download=True)\n",
        "testDataset = MNIST(root=\"content\",\n",
        "                    train=False,\n",
        "                    transform=transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()]),\n",
        "                    download=True)"
      ],
      "metadata": {
        "id": "TRURIUnrW_1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcjb8ky2PvGo"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpMGcu1KP07P"
      },
      "outputs": [],
      "source": [
        "class myModel(nn.Module) :\n",
        "  def __init__(self, opt) :\n",
        "    super(myModel, self).__init__()\n",
        "\n",
        "    inputDim, channels = opt[\"inputDim\"], opt[\"channels\"]\n",
        "\n",
        "    self.encoder = nn.Sequential(nn.Conv2d(inputDim, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU())\n",
        "    self.decoder = nn.Sequential(nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Upsample(scale_factor=2),\n",
        "                                 nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Upsample(scale_factor=2),\n",
        "                                 nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Upsample(scale_factor=2),\n",
        "                                 nn.Conv2d(channels, inputDim, kernel_size=3, stride=1, padding=1))\n",
        "\n",
        "  def forward(self, input) :\n",
        "    noisy = torch.clamp(input+torch.randn_like(input)*(50/255), 0, 1)\n",
        "\n",
        "    output = self.decoder(self.encoder(noisy))\n",
        "\n",
        "    return noisy, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wk4_cBzQU19"
      },
      "source": [
        "## Train DL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QJcgBk-QSsg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phpTOt47RjcB"
      },
      "source": [
        "### Fix Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81NJ5JxbRnaU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8F_Z5d3RlH-"
      },
      "outputs": [],
      "source": [
        "def fixSeed(seed) :\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Average Meter Instance"
      ],
      "metadata": {
        "id": "Jh4VCYXSswFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "oGUnMpzusxqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Code as a Function (Abstraction)"
      ],
      "metadata": {
        "id": "lhJ28-fU6Zk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(opt, trainDataset, testDataset, myModel, criterion) :\n",
        "  fixSeed(opt[\"seed\"])\n",
        "\n",
        "  trainDataLoader = DataLoader(trainDataset, batch_size=opt[\"batchSize\"], shuffle=True, drop_last=True)\n",
        "  testDataLoader = DataLoader(testDataset, batch_size=opt[\"batchSize\"], shuffle=False, drop_last=False)\n",
        "\n",
        "  fixSeed(opt[\"seed\"])\n",
        "  model = myModel(opt)\n",
        "  if opt[\"isCUDA\"] :\n",
        "    model = model.cuda()\n",
        "\n",
        "  summary(model, (opt[\"inputDim\"], opt[\"inputSize\"], opt[\"inputSize\"]))\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=opt[\"lr\"])\n",
        "\n",
        "  trainLoss, testLoss = AverageMeter(), AverageMeter()\n",
        "  trainLossList, testLossList = [], []\n",
        "  bestLoss = torch.inf\n",
        "\n",
        "  for epoch in range(1, opt[\"epochs\"]+1) :\n",
        "    trainBar = tqdm(trainDataLoader)\n",
        "    trainLoss.reset()\n",
        "\n",
        "    for data in trainBar :\n",
        "      input, target = data\n",
        "      if opt[\"isCUDA\"] :\n",
        "        input = input.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      pred = model(input)\n",
        "      loss = criterion(pred[-1], input)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      trainLoss.update(loss.item(), opt[\"batchSize\"])\n",
        "      trainBar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Train] < Loss:{trainLoss.avg:.6f} >\")\n",
        "\n",
        "    trainLossList.append(trainLoss.avg)\n",
        "\n",
        "    testBar = tqdm(testDataLoader)\n",
        "    testLoss.reset()\n",
        "\n",
        "    for data in testBar :\n",
        "      input, target = data\n",
        "      if opt[\"isCUDA\"] :\n",
        "        input = input.cuda()\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad() :\n",
        "        pred = model(input)\n",
        "        loss = criterion(pred[-1], input)\n",
        "\n",
        "        testLoss.update(loss.item(), opt[\"batchSize\"])\n",
        "\n",
        "        testBar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Test] < Loss:{testLoss.avg:.6f} >\")\n",
        "\n",
        "    testLossList.append(testLoss.avg)\n",
        "\n",
        "    if testLoss.avg < bestLoss :\n",
        "      bestLoss = testLoss.avg\n",
        "      torch.save(model.state_dict(), \"bestModel.pth\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"latestModel.pth\")\n",
        "\n",
        "  return (trainLossList, testLossList)"
      ],
      "metadata": {
        "id": "Toe0P0WH6c9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Training Option (Hyperparameter) Dictionary"
      ],
      "metadata": {
        "id": "ttFH7GYJq6c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = {\"inputSize\":32,\n",
        "       \"seed\":42,\n",
        "       \"inputDim\":1,\n",
        "       \"channels\":64,\n",
        "       \"batchSize\":16,\n",
        "       \"lr\":1e-4,\n",
        "       \"epochs\":5,\n",
        "       \"isCUDA\":torch.cuda.is_available()}"
      ],
      "metadata": {
        "id": "tXzQHG9aq9xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "VpE3M2q67qRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossList = train(opt, trainDataset, testDataset, myModel, nn.L1Loss())"
      ],
      "metadata": {
        "id": "yV7Jgs_77c57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrgUhJC67uzu"
      },
      "source": [
        "## Plot Training vs. Test Loss Graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_lIUGO11pAtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLsjFs3K7uzv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), lossList[0], label=\"Training Loss\")\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), lossList[1], label=\"Test Loss\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Latent Vector"
      ],
      "metadata": {
        "id": "RP4jlNz2e42r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Trained Model"
      ],
      "metadata": {
        "id": "5D-ZF3NhfGkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.load(\"/content/bestModel.pth\")\n",
        "\n",
        "model = myModel(opt)\n",
        "model.load_state_dict(weights)\n",
        "if opt[\"isCUDA\"] :\n",
        "  model = model.cuda()"
      ],
      "metadata": {
        "id": "lxfxB9W1fIPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Model Structure"
      ],
      "metadata": {
        "id": "8jjN8rSngATu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "Z_vtvoYCfOgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Test Dataset"
      ],
      "metadata": {
        "id": "jKM5ipJXgDEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testDataLoader = DataLoader(testDataset, batch_size=opt[\"batchSize\"], shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "qzOVvKahfPCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Result"
      ],
      "metadata": {
        "id": "CfJybQL2gHUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "fmP6OP91mjqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir \"output-samples\""
      ],
      "metadata": {
        "id": "RX3wQ7Qnnucv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numSample = 0\n",
        "\n",
        "for input, target in testDataLoader :\n",
        "  if opt[\"isCUDA\"] :\n",
        "    input = input.cuda()\n",
        "    noisy, output = model(input)\n",
        "\n",
        "  for i, label in enumerate(target) :\n",
        "    noisySample = noisy[i].squeeze(0).detach().cpu().numpy()\n",
        "    outputSample = output[i].squeeze(0).detach().cpu().numpy()\n",
        "    targetSample = input[i].squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    noisySample = np.clip(noisySample*225, 0, 255)\n",
        "    outputSample = np.clip(outputSample*225, 0, 255)\n",
        "    targetSample = np.clip(targetSample*225, 0, 255)\n",
        "\n",
        "    concat = np.hstack((noisySample, outputSample, targetSample))\n",
        "\n",
        "    cv2.imwrite(f\"output-samples/sample-{numSample}.png\", concat)\n",
        "    numSample += 1"
      ],
      "metadata": {
        "id": "Rg3_axMHfWcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Result"
      ],
      "metadata": {
        "id": "dtnr66aClFmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pduiqibYlIj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat = []\n",
        "\n",
        "for i in range(10) :\n",
        "  subConcat = []\n",
        "  for j in range(10) :\n",
        "    subConcat.append(cv2.imread(f\"/content/output-samples/sample-{i*10+j}.png\"))\n",
        "  concat.append(np.vstack(subConcat))\n",
        "\n",
        "concat = np.hstack(concat)"
      ],
      "metadata": {
        "id": "-l4XfDj5rdC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(concat)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kx2358DvmMUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDzKLleDO6dWEeubEhcmyH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}