{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JK-the-Ko/Thermo-Fluid-Dynamics-Experiment/blob/main/2023-2/%EC%97%B4%EC%9C%A0%EC%B2%B4%EA%B3%B5%ED%95%99%EC%8B%A4%ED%97%981_Week10_PyTorch_Multi_Class_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ97dC_jLHvF"
      },
      "source": [
        "# Multi-Class Classification Using PyTorch Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX6s-j7fq3hA"
      },
      "source": [
        "## Check NVIDIA GPU Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_I7cz1Sq6S1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9G6xRWOLRDP"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ult3kyAaLFPo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRo265QfLvCz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drug200.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Ycu33nLzHi"
      },
      "source": [
        "### View DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aos3Fo5cLyWZ"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Number of Data"
      ],
      "metadata": {
        "id": "d9ynzMU56gaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlerJUNzMx8_"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOzaz_jFMmGF"
      },
      "source": [
        "### Get Input and Target Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu_5mt8-L1TX"
      },
      "outputs": [],
      "source": [
        "inputData, targetData = df.drop(columns=[\"Drug\"], axis=1), df[\"Drug\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDrFJPifMpPW"
      },
      "source": [
        "### Get Input Feature Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nagAy9abMi2k"
      },
      "outputs": [],
      "source": [
        "inputData.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XscKeIwAM9jT"
      },
      "source": [
        "### Get Data Type of Input Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8A5rsbTM_Rj"
      },
      "outputs": [],
      "source": [
        "inputData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show Target Data"
      ],
      "metadata": {
        "id": "WpUJ3DRsxSbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetData"
      ],
      "metadata": {
        "id": "1ZTPJIWHxUYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkolzrgvNl_X"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "plnqX-sB6rgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataOHE = inputData.loc[:, [\"Sex\",\"BP\",\"Cholesterol\"]]"
      ],
      "metadata": {
        "id": "lws3xaV26s4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataOHE"
      ],
      "metadata": {
        "id": "0aD_ULIX68BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataOHE = pd.get_dummies(inputDataOHE)"
      ],
      "metadata": {
        "id": "y5fsS9ZO69zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataOHE"
      ],
      "metadata": {
        "id": "qAURyVwI6_Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Min-Max Normalization"
      ],
      "metadata": {
        "id": "Ft0do09XpX9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MinMaxNorm(dataFrame) :\n",
        "  return (dataFrame-dataFrame.min())/(dataFrame.max()-dataFrame.min())"
      ],
      "metadata": {
        "id": "57Jco6WDzhqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataMMN = MinMaxNorm(inputData.drop([\"Sex\",\"BP\",\"Cholesterol\"], axis=1))"
      ],
      "metadata": {
        "id": "-PY_od97xqA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataMMN"
      ],
      "metadata": {
        "id": "7W1rRKPuzvZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge Preprocessed Input Data"
      ],
      "metadata": {
        "id": "zFXqbbhj7O_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputData = pd.concat([inputDataOHE, inputDataMMN], axis=1)"
      ],
      "metadata": {
        "id": "V_b_Wocw7Tn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputData"
      ],
      "metadata": {
        "id": "tMYJCur27Zf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "Bo6IqyvFF-UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetData = pd.get_dummies(targetData)"
      ],
      "metadata": {
        "id": "5K4mDZSvGCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targetData"
      ],
      "metadata": {
        "id": "YpSidDG0IRhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3NJc3zONGtN"
      },
      "source": [
        "### Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfH3USUYNATV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData, targetData = np.array(inputData), np.array(targetData)"
      ],
      "metadata": {
        "id": "RwBj3WU50AdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RQa1TUVNZzl"
      },
      "outputs": [],
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(inputData, targetData, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOOOvXOzz7qM"
      },
      "outputs": [],
      "source": [
        "xTrain, xValid, yTrain, yValid = train_test_split(xTrain, yTrain, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ-l4w6HOIHX"
      },
      "outputs": [],
      "source": [
        "print(xTrain.shape, yTrain.shape)\n",
        "print(xValid.shape, yValid.shape)\n",
        "print(xTest.shape, yTest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXUpV3puOOlX"
      },
      "source": [
        "## Create PyTorch DataLoader Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhWPVY7tOKZc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTjqdBsVOVUu"
      },
      "outputs": [],
      "source": [
        "class myDataLoader(Dataset) :\n",
        "  def __init__(self, inputData:np.array, targetData:np.array) :\n",
        "    # Inheritance\n",
        "    super(myDataLoader, self).__init__()\n",
        "\n",
        "    # Initialize Variable\n",
        "    self.inputData = inputData\n",
        "    self.targetData = targetData\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    input = self.inputData[index, :]\n",
        "    target = self.targetData[index]\n",
        "\n",
        "    input = torch.as_tensor(input)\n",
        "    target = torch.as_tensor(target)\n",
        "\n",
        "    return {\"input\":input.float(), \"target\":target.float()}\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.inputData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz0-THJOPxvx"
      },
      "source": [
        "## Create PyTorch Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcjb8ky2PvGo"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpMGcu1KP07P"
      },
      "outputs": [],
      "source": [
        "class myModel(nn.Module) :\n",
        "  def __init__(self, inputDim:int, targetDim:int, channels:int) :\n",
        "    # Inheritance\n",
        "    super(myModel, self).__init__()\n",
        "\n",
        "    # Create MLP Layer Instance\n",
        "    self.layer0 = nn.Linear(inputDim, channels)\n",
        "    self.layer1 = nn.Linear(channels, channels)\n",
        "    self.layer2 = nn.Linear(channels, targetDim)\n",
        "\n",
        "  def forward(self, input) :\n",
        "    output = F.relu(self.layer0(input))\n",
        "    output = F.relu(self.layer1(output))\n",
        "    output = self.layer2(output)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Training Option (Hyperparameter) Dictionary"
      ],
      "metadata": {
        "id": "ttFH7GYJq6c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = {\"seed\":42,\n",
        "       \"numClass\":5,\n",
        "       \"batchSize\":8,\n",
        "       \"lr\":1e-3,\n",
        "       \"epochs\":50,\n",
        "       \"isCUDA\":torch.cuda.is_available()}"
      ],
      "metadata": {
        "id": "tXzQHG9aq9xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wk4_cBzQU19"
      },
      "source": [
        "## Train DL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QJcgBk-QSsg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phpTOt47RjcB"
      },
      "source": [
        "### Fix Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81NJ5JxbRnaU"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8F_Z5d3RlH-"
      },
      "outputs": [],
      "source": [
        "def fixSeed(seed) :\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Average Meter Instance"
      ],
      "metadata": {
        "id": "Jh4VCYXSswFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val*n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "oGUnMpzusxqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Accuracy Computation Function"
      ],
      "metadata": {
        "id": "fBn8NVKk8Pqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeAcc(pred, target) :\n",
        "  acc = (torch.argmax(pred, dim=1)==torch.argmax(target, dim=1)).sum()/pred.size(0)\n",
        "\n",
        "  return acc"
      ],
      "metadata": {
        "id": "B8qpzXhw8Org"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Code as a Function (Abstraction)"
      ],
      "metadata": {
        "id": "lhJ28-fU6Zk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(opt, dataset, criterion) :\n",
        "  fixSeed(opt[\"seed\"])\n",
        "\n",
        "  trainDataLoader = DataLoader(myDataLoader(dataset[\"xTrain\"], dataset[\"yTrain\"]), batch_size=opt[\"batchSize\"], shuffle=True, drop_last=True)\n",
        "  validDataLoader = DataLoader(myDataLoader(dataset[\"xValid\"], dataset[\"yValid\"]), batch_size=opt[\"batchSize\"], shuffle=False, drop_last=False)\n",
        "\n",
        "  fixSeed(opt[\"seed\"])\n",
        "  model = myModel(xTrain.shape[1], opt[\"numClass\"], 64)\n",
        "  if opt[\"isCUDA\"] :\n",
        "    model = model.cuda()\n",
        "\n",
        "  summary(model, (1, dataset[\"xTrain\"].shape[1]))\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=opt[\"lr\"])\n",
        "\n",
        "  trainLoss, validLoss = AverageMeter(), AverageMeter()\n",
        "  trainAcc, validAcc = AverageMeter(), AverageMeter()\n",
        "  trainLossList, validLossList = [], []\n",
        "  trainAccList, validAccList = [], []\n",
        "  bestAcc = 0\n",
        "\n",
        "  for epoch in range(1, opt[\"epochs\"]+1) :\n",
        "    trainBar = tqdm(trainDataLoader)\n",
        "    trainLoss.reset(), trainAcc.reset()\n",
        "\n",
        "    for data in trainBar :\n",
        "      input, target = data[\"input\"], data[\"target\"]\n",
        "      if opt[\"isCUDA\"] :\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred = model(input)\n",
        "      loss = criterion(pred, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      trainLoss.update(loss.item(), opt[\"batchSize\"])\n",
        "      trainAcc.update(computeAcc(pred, target).item(), opt[\"batchSize\"])\n",
        "      trainBar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Train] < Accuracy:{trainAcc.avg:.6f} | Loss:{trainLoss.avg:.6f} >\")\n",
        "\n",
        "    trainLossList.append(trainLoss.avg)\n",
        "    trainAccList.append(trainAcc.avg)\n",
        "\n",
        "    validBar = tqdm(validDataLoader)\n",
        "    validLoss.reset(), validAcc.reset()\n",
        "\n",
        "    for data in validBar :\n",
        "      input, target = data[\"input\"], data[\"target\"]\n",
        "      if opt[\"isCUDA\"] :\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad() :\n",
        "        pred = model(input)\n",
        "        loss = criterion(pred, target)\n",
        "\n",
        "        validLoss.update(loss.item(), opt[\"batchSize\"])\n",
        "        validAcc.update(computeAcc(pred, target).item(), opt[\"batchSize\"])\n",
        "        validBar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Valid] < Accuracy:{validAcc.avg:.6f} | Loss:{trainLoss.avg:.6f} >\")\n",
        "\n",
        "    validLossList.append(validLoss.avg)\n",
        "    validAccList.append(validAcc.avg)\n",
        "\n",
        "    if validAcc.avg > bestAcc :\n",
        "      bestAcc = validAcc.avg\n",
        "      torch.save(model.state_dict(), \"bestModel.pth\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"latestModel.pth\")\n",
        "\n",
        "  return (trainLossList, validLossList), (trainAccList, validAccList)"
      ],
      "metadata": {
        "id": "Toe0P0WH6c9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "VpE3M2q67qRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossList, accList = train(opt,\n",
        "                          {\"xTrain\":xTrain, \"yTrain\":yTrain, \"xValid\":xValid, \"yValid\":yValid},\n",
        "                          nn.CrossEntropyLoss())"
      ],
      "metadata": {
        "id": "yV7Jgs_77c57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrgUhJC67uzu"
      },
      "source": [
        "## Plot Training vs. Validation Loss Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLsjFs3K7uzv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), lossList[0], label=\"Training Loss\")\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), lossList[1], label=\"Validation Loss\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"BCE Loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfMgjzvi9dYX"
      },
      "source": [
        "## Plot Training vs. Validation Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0N1aiik9dYd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), accList[0], label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0, opt[\"epochs\"], 1), accList[1], label=\"Validation Accuracy\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Code as a Function (Abstraction)"
      ],
      "metadata": {
        "id": "TWl44qH29BS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(opt, inputData, modelPath) :\n",
        "  weights = torch.load(modelPath)\n",
        "\n",
        "  model = myModel(xTrain.shape[1], opt[\"numClass\"], 64)\n",
        "  model.load_state_dict(weights)\n",
        "  if opt[\"isCUDA\"] :\n",
        "    model = model.cuda()\n",
        "\n",
        "  inputDataTensor = torch.as_tensor(inputData).float()\n",
        "\n",
        "  predList = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad() :\n",
        "    with tqdm(total=inputData.shape[0]) as pBar :\n",
        "      for inputData in inputDataTensor :\n",
        "        if opt[\"isCUDA\"] :\n",
        "          inputData = inputData.cuda()\n",
        "\n",
        "        pred = model(inputData)\n",
        "        predList.append(torch.argmax(pred, dim=0).detach().cpu().item())\n",
        "\n",
        "        pBar.update()\n",
        "\n",
        "  return predList"
      ],
      "metadata": {
        "id": "jwfLPKdk9ClT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Result"
      ],
      "metadata": {
        "id": "6LBdxtVa8Pjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predList = inference(opt, xTest, \"/content/bestModel.pth\")"
      ],
      "metadata": {
        "id": "kMi_gTRL8Pjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predList"
      ],
      "metadata": {
        "id": "FLS_XvM-BKgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding to Label-Encoding"
      ],
      "metadata": {
        "id": "hRCftqv3Kt8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yTest"
      ],
      "metadata": {
        "id": "Fo9BnDoKJ8lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTest = np.argmax(yTest, axis=1)"
      ],
      "metadata": {
        "id": "t4uWfn1MKmOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTest"
      ],
      "metadata": {
        "id": "b1sM7tFPKrnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantitative Assessment"
      ],
      "metadata": {
        "id": "URfarsx7ARdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "q7GlfZO6AXrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accScore = accuracy_score(yTest, predList)\n",
        "print(accScore)"
      ],
      "metadata": {
        "id": "3SH1Bt3p8Pjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(yTest, predList)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "J-hHT2HfB-Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsRp = classification_report(yTest, predList)\n",
        "print(clsRp)"
      ],
      "metadata": {
        "id": "zhT7r62ACAvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTqwm8YFaeLnhOvg/WPuHZ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}