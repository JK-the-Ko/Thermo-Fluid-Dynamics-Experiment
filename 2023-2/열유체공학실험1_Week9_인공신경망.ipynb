{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1S4rSDn02q1ruOP6xDJ3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JK-the-Ko/Thermo-Fluid-Dynamics-Experiment/blob/main/2023-2/%EC%97%B4%EC%9C%A0%EC%B2%B4%EA%B3%B5%ED%95%99%EC%8B%A4%ED%97%981_Week9_%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "w4pwoaQBRZEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "fCmajizLRbAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Cpux903NhlD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Function"
      ],
      "metadata": {
        "id": "W95iyhCoRc4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function(x1, x2, x3) :\n",
        "  return np.power(x1,2) + 4*np.power(x2,2) - 10*x3"
      ],
      "metadata": {
        "id": "2tnz6kmNN_xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deltaX = 1e-3\n",
        "x1, x2, x3 = np.arange(2, 6, deltaX), np.arange(-4, 0, deltaX), np.arange(0, 4, deltaX)"
      ],
      "metadata": {
        "id": "V0R2zcSSOQoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = function(x1, x2, x3)"
      ],
      "metadata": {
        "id": "xjzmw9TKOd1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Histogram"
      ],
      "metadata": {
        "id": "SuF0CyfeRnef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(y, bins = 100)\n",
        "plt.xlabel(\"value\")\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.title(\"Output Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "njrULeh5Ofm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Function"
      ],
      "metadata": {
        "id": "PyI2MzoSRNG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "rSIiOai7DH5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid"
      ],
      "metadata": {
        "id": "l84szhBbUau6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Sigmoid(input:np.array)->np.array :\n",
        "  return np.power(1 + np.exp(-input), -1)"
      ],
      "metadata": {
        "id": "RnXY7nT_Uau6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Sampling"
      ],
      "metadata": {
        "id": "mVlBXL-2Uau6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numSample = 25"
      ],
      "metadata": {
        "id": "q0K3GK8wUau7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomVariables = np.random.randn((numSample))"
      ],
      "metadata": {
        "id": "a-4iBSuLUau7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compare Result"
      ],
      "metadata": {
        "id": "4fWmulpmUau7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(np.arange(numSample), randomVariables, label=\"Original\", marker=\"X\", s=250)\n",
        "plt.scatter(np.arange(numSample), Sigmoid(randomVariables), label=\"Sigmoid\", marker=\".\", s=250)\n",
        "\n",
        "for i in range(numSample) :\n",
        "  deltaY = Sigmoid(randomVariables[i]) - randomVariables[i]\n",
        "  if deltaY != 0 :\n",
        "    plt.arrow(i, randomVariables[i], 0, deltaY, head_width = 0.25, head_length = 0.05, fc = \"k\", ec = \"k\")\n",
        "\n",
        "plt.xlabel(\"# sample\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.title(\"Result Comparison (Sigmoid)\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AmqfiqDnUau7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rectified Linear Unit (ReLU)"
      ],
      "metadata": {
        "id": "Oy9EMNZ_ROXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(input:np.array)->np.array :\n",
        "  return np.where(input > 0, input, 0)"
      ],
      "metadata": {
        "id": "Oci-Y5IgQExX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Sampling"
      ],
      "metadata": {
        "id": "Irc3oiTgR8sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numSample = 25"
      ],
      "metadata": {
        "id": "DXWi0v8CS_DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomVariables = np.random.randn((numSample))"
      ],
      "metadata": {
        "id": "99yDg2vTRRik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compare Result"
      ],
      "metadata": {
        "id": "BMfmn_kcR9_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(np.arange(numSample), randomVariables, label=\"Original\", marker=\"X\", s=250)\n",
        "plt.scatter(np.arange(numSample), ReLU(randomVariables), label=\"ReLU\", marker=\".\", s=250)\n",
        "\n",
        "for i in range(numSample) :\n",
        "  deltaY = ReLU(randomVariables[i]) - randomVariables[i]\n",
        "  if deltaY != 0 :\n",
        "    plt.arrow(i, randomVariables[i], 0, deltaY, head_width = 0.25, head_length = 0.05, fc = \"k\", ec = \"k\")\n",
        "\n",
        "plt.xlabel(\"# sample\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.title(\"Result Comparison (ReLU)\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OvyNKxRRyi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build 2-Layer Neural Network"
      ],
      "metadata": {
        "id": "xgIvG2txRVat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "g1XcEyC17t8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNeuralNetwork :\n",
        "  def __init__(self, numInputs:int, numHiddenLayerNodes:int, numOutputs:int, seed:int) :\n",
        "    # Initialize Variables\n",
        "    self.numInputs = numInputs\n",
        "    self.numHiddenLayerNodes = numHiddenLayerNodes\n",
        "    self.numOutputs = numOutputs\n",
        "    self.seed = seed\n",
        "\n",
        "    # Initialize Model Parameters\n",
        "    self.initializeWeights()\n",
        "\n",
        "  def initializeWeights(self) :\n",
        "    # Fix Seed\n",
        "    np.random.seed(self.seed)\n",
        "\n",
        "    # Initialize Model Parameters\n",
        "    self.layer1Weights = np.random.random((self.numInputs, self.numHiddenLayerNodes))\n",
        "    self.layer2Weights = np.random.random((self.numHiddenLayerNodes, self.numOutputs))\n",
        "\n",
        "    # Print Model Parameters\n",
        "    print(\"Model Parameters Initialized!\")\n",
        "    print(f\"# Parameters : {self.layer1Weights.size + self.layer2Weights.size}\")\n",
        "    print(f\"Layer 1 Size : {self.layer1Weights.shape}\")\n",
        "    print(f\"Layer 1 Weights: {self.layer1Weights.flatten()}\")\n",
        "    print(f\"Layer 2 Size : {self.layer2Weights.shape}\")\n",
        "    print(f\"Layer 2 Weights: {self.layer2Weights.flatten()}\")\n",
        "\n",
        "  def LeakyReLU(self, input:np.array)->np.array :\n",
        "    return np.where(input>0, input, -0.2*input)\n",
        "\n",
        "  def predict(self, input:np.array)->np.array :\n",
        "    output = self.LeakyReLU(np.matmul(input, self.layer1Weights))\n",
        "    output = np.matmul(output, self.layer2Weights)\n",
        "    return output\n",
        "\n",
        "  def computeMSELoss(self, pred:np.array, target:np.array)->float :\n",
        "    return np.power(target-pred, 2).mean()\n",
        "\n",
        "  def backPropagation(self, input:np.array, target:np.array)->np.array :\n",
        "    # Compute Each Layer Output\n",
        "    stg1Output = np.matmul(input, self.layer1Weights)\n",
        "    stg2Output = self.LeakyReLU(stg1Output)\n",
        "    stg3Output = np.matmul(stg2Output, self.layer2Weights)\n",
        "\n",
        "    # Compute Gradient of Each Parameter\n",
        "    gradientLayer2 = -np.matmul(stg2Output.reshape(-1,1), (target-stg3Output).reshape(1,-1))\n",
        "    gradientLayer1 = -np.matmul(input.reshape(-1,1), (target-stg3Output).mean() * (self.layer2Weights * np.where(stg2Output>0, 1, -0.2)).sum(axis=1).reshape(1,-1))\n",
        "\n",
        "    return gradientLayer1, gradientLayer2\n",
        "\n",
        "  def train(self, inputTrain:np.array, targetTrain:np.array, inputTest:np.array, targetTest:np.array,batchSize:int, learningRate:float)->list :\n",
        "    # Create List Instance\n",
        "    trainLossList, testLossList = [],[]\n",
        "\n",
        "    # Initialize Varaibles\n",
        "    loss = 0\n",
        "\n",
        "    # Compute Iteration\n",
        "    iteration = len(inputTrain) // batchSize\n",
        "\n",
        "    print(\"Training Phase\")\n",
        "    with tqdm(total = iteration) as pBar :\n",
        "      for i in range(iteration) :\n",
        "        # Initialize Varaibles\n",
        "        gradientLayer1, gradientLayer2 = 0, 0\n",
        "        subInputTrain, subTargetTrain = inputTrain[i*batchSize : (i+1)*batchSize], targetTrain[i*batchSize : (i+1)*batchSize]\n",
        "\n",
        "        for j in range(batchSize) :\n",
        "          # Feed Forward\n",
        "          pred = self.predict(subInputTrain[j])\n",
        "\n",
        "          # Compute MSE Loss\n",
        "          loss += self.computeMSELoss(pred, subTargetTrain[j])\n",
        "\n",
        "          # Compute Gradient of Each Data\n",
        "          subGradientLayer1, subGradientLayer2 = self.backPropagation(subInputTrain[j], subTargetTrain[j])\n",
        "          gradientLayer1 += subGradientLayer1\n",
        "          gradientLayer2 += subGradientLayer2\n",
        "\n",
        "        # Compute Average Gradient\n",
        "        gradientLayer1 /= batchSize\n",
        "        gradientLayer2 /= batchSize\n",
        "\n",
        "        # Update Model Parameters\n",
        "        self.layer1Weights -= learningRate * gradientLayer1\n",
        "        self.layer2Weights -= learningRate * gradientLayer2\n",
        "\n",
        "        # Update TQDM Bar\n",
        "        pBar.update()\n",
        "\n",
        "    # Compute Average Loss\n",
        "    loss /= len(inputTrain)\n",
        "    trainLossList.append(loss)\n",
        "\n",
        "    # Initialize Varaibles\n",
        "    loss = 0\n",
        "\n",
        "    # Compute Iteration\n",
        "    iteration = len(inputTest) // batchSize\n",
        "\n",
        "    print(\"Test Phase\")\n",
        "    with tqdm(total = iteration) as pBar :\n",
        "      for i in range(iteration) :\n",
        "        # Initialize Varaibles\n",
        "        subInputTest, subTargetTest = inputTest[i*batchSize : (i+1)*batchSize], targetTest[i*batchSize : (i+1)*batchSize]\n",
        "\n",
        "        for j in range(batchSize) :\n",
        "          # Feed Forward\n",
        "          pred = self.predict(subInputTest[j])\n",
        "\n",
        "          # Compute MSE Loss\n",
        "          loss += self.computeMSELoss(pred, subTargetTest[j])\n",
        "\n",
        "        # Update TQDM Bar\n",
        "        pBar.update()\n",
        "\n",
        "     # Compute Average Loss\n",
        "      loss /= len(inputTest)\n",
        "      testLossList.append(loss)\n",
        "\n",
        "    return trainLossList, testLossList"
      ],
      "metadata": {
        "id": "Da2IF_ftQlv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Dataset"
      ],
      "metadata": {
        "id": "iAJhSnm4kXdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputDataset, targetDataset = [], []\n",
        "\n",
        "for i in range(len(y)) :\n",
        "  inputDataset.append(np.array([x1[i], x2[i], x3[i]]))\n",
        "  targetDataset.append(np.array(y[i]))\n",
        "\n",
        "inputDataset, targetDataset = np.array(inputDataset), np.array(targetDataset)"
      ],
      "metadata": {
        "id": "lmjqhjHDiOIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input Dataset Size : {inputDataset.shape}\")\n",
        "print(f\"Target Dataset Size : {targetDataset.shape}\")"
      ],
      "metadata": {
        "id": "t4mnF4nglXzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Dataset"
      ],
      "metadata": {
        "id": "Xos9NQi170FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EEnihcnE70_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(inputDataset, targetDataset, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "oi58nD_J730B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Dataset Size : {xTrain.shape[0]}\")\n",
        "print(f\"Test Dataset Size : {xTest.shape[0]}\")"
      ],
      "metadata": {
        "id": "BWb5KZ8n8AW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Neural Network Instance"
      ],
      "metadata": {
        "id": "Pf2t03OAaMv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numInputs, numHiddenLayerNodes, numOutputs, seed = 3, 2, 1, 42"
      ],
      "metadata": {
        "id": "mADKNfkGmNQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TwoLayerNeuralNetwork(numInputs, numHiddenLayerNodes, numOutputs, seed)"
      ],
      "metadata": {
        "id": "YqEZn7XDUTzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine Hyperparameters"
      ],
      "metadata": {
        "id": "AwbenO-LmWp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numEpoch = 200"
      ],
      "metadata": {
        "id": "xpHWA7vi1T7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize, learningRate = 128, 1e-4"
      ],
      "metadata": {
        "id": "qHUEWNcBmaBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "JeWyr2yWmZLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model, numEpoch, batchSize, learningRate) :\n",
        "  trainLossList, testLossList = [],[]\n",
        "  bestLoss = np.inf\n",
        "\n",
        "  for epoch in range(numEpoch) :\n",
        "    print(f\"[Current Epoch : {epoch + 1}]\")\n",
        "    trainLoss, testLoss = model.train(xTrain, yTrain, xTest, yTest, batchSize, learningRate)\n",
        "    trainLossList += trainLoss\n",
        "    testLossList += testLoss\n",
        "\n",
        "    if testLoss[0] < bestLoss :\n",
        "      bestLoss = testLoss[0]\n",
        "      bestWeight = [model.layer1Weights, model.layer2Weights]\n",
        "\n",
        "  return trainLossList, testLossList, bestWeight"
      ],
      "metadata": {
        "id": "2D2R0Dxa2zuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLossList, testLossList, bestWeight = trainModel(model, numEpoch, batchSize, learningRate)"
      ],
      "metadata": {
        "id": "HP2tzYbmldOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Loss Curve"
      ],
      "metadata": {
        "id": "C8z7IiI4_vk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(np.arange(len(trainLossList)), trainLossList, label = \"Train Loss\")\n",
        "plt.plot(np.arange(len(testLossList)), testLossList, label = \"Test Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"Training Result\")\n",
        "plt.legend(loc = \"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sN66LcOC3OVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Optimized Parameters"
      ],
      "metadata": {
        "id": "E7DyB6NW_yRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min(testLossList)"
      ],
      "metadata": {
        "id": "cbn50gJaAJoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bestWeight[0])\n",
        "print(bestWeight[1])"
      ],
      "metadata": {
        "id": "O9nlgjkJ_rlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Result with Trained Neural Network"
      ],
      "metadata": {
        "id": "J0wFo8Wi_1e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1Weights, model.layer2Weights = bestWeight[0], bestWeight[1]"
      ],
      "metadata": {
        "id": "eHsRVCeA_tB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yPredNN = []\n",
        "\n",
        "for subXTest in xTest :\n",
        "  yPredNN.append(model.predict(subXTest)[0])"
      ],
      "metadata": {
        "id": "Wx_LgjLkASPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Result with Linear Regression Model"
      ],
      "metadata": {
        "id": "G_HA5HRkBFN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getParameter(x: np.array, y: np.array) :\n",
        "  xT = np.transpose(x)\n",
        "  output = np.matmul(np.matmul(np.linalg.inv(np.matmul(xT, x)), xT), y)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "lkTZZxg-BHAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "betaHat = getParameter(xTrain, yTrain)"
      ],
      "metadata": {
        "id": "_6MgSyVSBSUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "betaHat"
      ],
      "metadata": {
        "id": "qgWhYnMMBUo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yPredLR = np.matmul(xTest, betaHat).tolist()"
      ],
      "metadata": {
        "id": "QAwywSf3BWHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Result"
      ],
      "metadata": {
        "id": "vJ0XImuOBq-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute MSE Loss"
      ],
      "metadata": {
        "id": "IHS6VmFwCaMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSELoss(yPred:np.array, yTrue:np.array)->float:\n",
        "  return np.power(yPred-yTrue, 2).mean()"
      ],
      "metadata": {
        "id": "CN4r-nC-CbSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Neural Network (NN) MSE Loss : {MSELoss(np.array(yPredNN), yTest)}\")\n",
        "print(f\"Linear Regression (LR) MSE Loss : {MSELoss(np.array(yPredLR), yTest)}\")"
      ],
      "metadata": {
        "id": "OdPVhb35CmnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Bar Chart"
      ],
      "metadata": {
        "id": "gyyBlTMXCY0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (20, 10))\n",
        "idx = np.asarray([i for i in range(50)])\n",
        "width = 0.2\n",
        "\n",
        "ax.bar(idx, yTest[:50], width = width)\n",
        "ax.bar(idx+width, yPredNN[:50], width = width)\n",
        "ax.bar(idx+2*width, yPredLR[:50], width = width)\n",
        "ax.set_xticks(idx)\n",
        "ax.legend([\"Ground Truth\", \"NN\", \"LR\"])\n",
        "ax.set_xlabel(\"# samples\")\n",
        "ax.set_ylabel(\"Value\")\n",
        "ax.set_title(\"Result Comparison\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wbfy-HIzBf7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}