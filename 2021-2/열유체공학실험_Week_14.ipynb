{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "열유체공학실험_Week_14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIKLmiOBRUE48SE8bdz1AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JK-the-Ko/Thermo_Fluid_Dynamics_Experiment/blob/main/2021_2/%EC%97%B4%EC%9C%A0%EC%B2%B4%EA%B3%B5%ED%95%99%EC%8B%A4%ED%97%98_Week_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFT1NIjIAJ6X"
      },
      "source": [
        "**Check GPU Connection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEWRTjkgAMSk"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS3sw48k3MK6"
      },
      "source": [
        "**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4grqzoHK2OAw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNgKcfEB3ORF"
      },
      "source": [
        "**Load Fashion CIFAR10 Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D73B3MDV2fKP"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs9xPWEw6omL"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Preprocessing**"
      ],
      "metadata": {
        "id": "2gqK_Q4q8jji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CLAHE (Histogram Equalization) "
      ],
      "metadata": {
        "id": "AP7CbAw-8mDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "3NbSU0Ev83W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Create CLAHE Instance"
      ],
      "metadata": {
        "id": "ripliVif9j9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (2, 2)) "
      ],
      "metadata": {
        "id": "4TZGgMpo80hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clahe, x_test_clahe = list(), list()"
      ],
      "metadata": {
        "id": "O2v2JhHU8_gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Apply CLAHE"
      ],
      "metadata": {
        "id": "goJrDGIY9mS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, image in enumerate(x_train) :\n",
        "  r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
        "  r, g, b = clahe.apply(r), clahe.apply(g), clahe.apply(b)\n",
        "  r, g, b = np.expand_dims(r, axis = -1), np.expand_dims(g, axis = -1), np.expand_dims(b, axis = -1)\n",
        "  image = np.concatenate((r, g, b), axis = -1)\n",
        "  x_train_clahe.append(image)"
      ],
      "metadata": {
        "id": "NyxYSj7b9EsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, image in enumerate(x_test) :\n",
        "  r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
        "  r, g, b = clahe.apply(r), clahe.apply(g), clahe.apply(b)\n",
        "  r, g, b = np.expand_dims(r, axis = -1), np.expand_dims(g, axis = -1), np.expand_dims(b, axis = -1)\n",
        "  image = np.concatenate((r, g, b), axis = -1)\n",
        "  x_test_clahe.append(image)"
      ],
      "metadata": {
        "id": "xv29dEHDQTIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Convert into Numpy Array"
      ],
      "metadata": {
        "id": "Djy7rrYo92VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clahe = np.array(x_train_clahe)\n",
        "x_test_clahe = np.array(x_test_clahe)"
      ],
      "metadata": {
        "id": "tu17JrZw9sjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Comparison**"
      ],
      "metadata": {
        "id": "w2QpV-OLmzP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_stack = np.hstack((x_train[0], x_train_clahe[0]))"
      ],
      "metadata": {
        "id": "ISZ3DnQknJ3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image_stack)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dpw1W8ErnISW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXunmfZK380i"
      },
      "source": [
        "**Data Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLGKihOU3_S5"
      },
      "source": [
        "* Min-Max Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "269w0T8M3kd4"
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWkA0grU54q5"
      },
      "source": [
        "* One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oao3koM45zXA"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Qtcpf8cEjF"
      },
      "source": [
        "* Make CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VzHAU1t2kYR"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE-TSFCqcDF1"
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWWIMpeKcDF1"
      },
      "source": [
        "model.add(layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\", input_shape = input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(128, activation = \"relu\"))\n",
        "model.add(layers.Dense(128, activation = \"relu\"))\n",
        "model.add(layers.Dense(num_classes, \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klK9XwgXcJLa"
      },
      "source": [
        "* Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmwoE9O8y6Lr"
      },
      "source": [
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRdQaZfacORv"
      },
      "source": [
        "model.compile(optimizer = optimizers.Adam(learning_rate = 1e-3), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxqewaoDcGTh"
      },
      "source": [
        "* Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzAQuZCkEMgx"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "NSDtFnt5NoUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "u9fHqnkRPfft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Preprocessed Data Set"
      ],
      "metadata": {
        "id": "I6F0MgyDOlzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clahe = x_train_clahe / 255\n",
        "x_test_clahe = x_test_clahe / 255"
      ],
      "metadata": {
        "id": "3OCfLIfEOQjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EdSBqUzOpCo"
      },
      "source": [
        "* Make CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMFwJALROpCo"
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlL-K19OpCo"
      },
      "source": [
        "model.add(layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\", input_shape = input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(128, activation = \"relu\"))\n",
        "model.add(layers.Dense(128, activation = \"relu\"))\n",
        "model.add(layers.Dense(num_classes, \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = optimizers.Adam(learning_rate = 1e-3), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "872TRHOTPLqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train_clahe, y_train, batch_size = batch_size, epochs = epochs, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "j8R4uc2DOcaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_clahe, y_test, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "shIMvb3pQhrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**"
      ],
      "metadata": {
        "id": "wiWzbBjwAkcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.compile(optimizer = **optimizers.Adam(learning_rate = 1e-3)**, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "jpMheL9uAs1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = optimizers.Adam(learning_rate = 1e-3), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "HOvv-MUFAvQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
